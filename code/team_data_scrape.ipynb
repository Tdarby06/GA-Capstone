{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = [\n",
    "    '1995', '1996', '1997', '1998', '1999',\n",
    "    '2000', '2001', '2002', '2003', '2004',\n",
    "    '2005', '2006', '2007', '2008', '2009',\n",
    "    '2010', '2011', '2012', '2013', '2014',\n",
    "    '2015', '2016', '2017', '2018', '2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AL_West = ['HOU', 'TEX', 'SEA', 'OAK'] #'LAA' #AL West\n",
    "# AL_East = ['NYY', 'BOS', 'TOR', 'BAL',] #'TBR' #AL East\n",
    "# AL_Central = ['MIN', 'CLE', 'CHW', 'KCR', 'DET'] #AL Central\n",
    "# NL_West = ['LAD', 'SFG', 'COL', 'SDP'] #'ARI', #NL West\n",
    "# NL_East = ['ATL', 'NYM', 'PHI'] #'WSN', 'MIA', #NL East\n",
    "# NL_Central = ['STL', 'MIL', 'CHC', 'CIN', 'PIT'] #NL Central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created list of teams to scrape. These teams did not create issues with the url in the years\n",
    "#requested and were scraped together for efficency.\n",
    "\n",
    "MLB = ['LAD','SFG','COL','SDP','ATL',\n",
    "    'NYM','PHI','STL','MIL','CHC',\n",
    "    'CIN','PIT','HOU','TEX','SEA',\n",
    "    'OAK','NYY','BOS','TOR','BAL',\n",
    "    'MIN','CLE','CHW','KCR','DET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAD\n",
      "done!\n",
      "SFG\n",
      "done!\n",
      "COL\n",
      "done!\n",
      "SDP\n",
      "done!\n",
      "ATL\n",
      "done!\n",
      "NYM\n",
      "done!\n",
      "PHI\n",
      "done!\n",
      "STL\n",
      "done!\n",
      "MIL\n",
      "done!\n",
      "CHC\n",
      "done!\n",
      "CIN\n",
      "done!\n",
      "PIT\n",
      "done!\n",
      "HOU\n",
      "done!\n",
      "TEX\n",
      "done!\n",
      "SEA\n",
      "done!\n",
      "OAK\n",
      "done!\n",
      "NYY\n",
      "done!\n",
      "BOS\n",
      "done!\n",
      "TOR\n",
      "done!\n",
      "BAL\n",
      "done!\n",
      "MIN\n",
      "done!\n",
      "CLE\n",
      "done!\n",
      "CHW\n",
      "done!\n",
      "KCR\n",
      "done!\n",
      "DET\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "for team in MLB:\n",
    "    club = []\n",
    "    print(team)\n",
    "    for year in year_list:\n",
    "        url = f'https://www.baseball-reference.com/teams/{team}/{year}-schedule-scores.shtml'\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.content)\n",
    "        season= []\n",
    "\n",
    "        for row in soup.find('div', {'id':'all_team_schedule'}).find('tbody').find_all('tr'):\n",
    "            game = {}\n",
    "            try:\n",
    "                game['game#'] = row.find('th', {'data-stat':'team_game'}).text\n",
    "                game['day'] = (row.find('td', {'data-stat':'date_game'}).text).split()[0].strip(',')\n",
    "                game['date'] = row.find('td').attrs['csk']\n",
    "                game['team'] = row.find('td', {'data-stat':'team_ID'}).text\n",
    "                game['home_away'] = row.find('td', {'data-stat':'homeORvis'}).text\n",
    "                game['opp'] = row.find('td', {'data-stat':'opp_ID'}).text\n",
    "                game['win_loss'] = row.find('td', {'data-stat':'win_loss_result'}).text\n",
    "                game['r'] = row.find('td', {'data-stat':'R'}).text\n",
    "                game['ra'] = row.find('td', {'data-stat':'RA'}).text\n",
    "                game['innings'] = row.find('td', {'data-stat':'extra_innings'}).text\n",
    "                game['record'] = row.find('td', {'data-stat':'win_loss_record'}).text\n",
    "                game['divison_rank'] = row.find('td', {'data-stat':'rank'}).text\n",
    "                game['games_back'] = row.find('td', {'data-stat':'games_back'}).text\n",
    "                game['winning_pitcher'] = row.find('td', {'data-stat':'winning_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "                game['losing_pitcher'] = row.find('td', {'data-stat':'losing_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "                game['game_duration'] = row.find('td', {'data-stat':'time_of_game'}).text\n",
    "                game['day_night'] = row.find('td', {'data-stat':'day_or_night'}).text\n",
    "                game['attendance'] = row.find('td', {'data-stat':'attendance'}).text\n",
    "                game['streak'] = row.find('td', {'data-stat':'win_loss_streak'}).text\n",
    "                game['saving_pitcher'] = row.find('td', {'data-stat':'saving_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "            except:\n",
    "                pass\n",
    "            if game['game#'] != 'Gm#':\n",
    "                season.append(game)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        club.append(pd.DataFrame(season))\n",
    "        sleep(3)\n",
    "    df = pd.concat(club)\n",
    "    df.to_csv(f'../data/{team}_data.csv', index = False)\n",
    "    print('done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teams scraped individually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Angels = ['LAA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list2 = ['2005', '2006', '2007', '2008', '2009',\n",
    "    '2010', '2011', '2012', '2013', '2014',\n",
    "    '2015', '2016', '2017', '2018', '2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAA\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "for team in Angels:\n",
    "    club = []\n",
    "    print(team)\n",
    "    for year in year_list2:\n",
    "        url = f'https://www.baseball-reference.com/teams/{team}/{year}-schedule-scores.shtml'\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.content)\n",
    "        season= []\n",
    "\n",
    "        for row in soup.find('div', {'id':'all_team_schedule'}).find('tbody').find_all('tr'):\n",
    "            game = {}\n",
    "            try:\n",
    "                game['game#'] = row.find('th', {'data-stat':'team_game'}).text\n",
    "                game['day'] = (row.find('td', {'data-stat':'date_game'}).text).split()[0].strip(',')\n",
    "                game['date'] = row.find('td').attrs['csk']\n",
    "                game['team'] = row.find('td', {'data-stat':'team_ID'}).text\n",
    "                game['home_away'] = row.find('td', {'data-stat':'homeORvis'}).text\n",
    "                game['opp'] = row.find('td', {'data-stat':'opp_ID'}).text\n",
    "                game['win_loss'] = row.find('td', {'data-stat':'win_loss_result'}).text\n",
    "                game['r'] = row.find('td', {'data-stat':'R'}).text\n",
    "                game['ra'] = row.find('td', {'data-stat':'RA'}).text\n",
    "                game['innings'] = row.find('td', {'data-stat':'extra_innings'}).text\n",
    "                game['record'] = row.find('td', {'data-stat':'win_loss_record'}).text\n",
    "                game['divison_rank'] = row.find('td', {'data-stat':'rank'}).text\n",
    "                game['games_back'] = row.find('td', {'data-stat':'games_back'}).text\n",
    "                game['winning_pitcher'] = row.find('td', {'data-stat':'winning_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "                game['losing_pitcher'] = row.find('td', {'data-stat':'losing_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "                game['game_duration'] = row.find('td', {'data-stat':'time_of_game'}).text\n",
    "                game['day_night'] = row.find('td', {'data-stat':'day_or_night'}).text\n",
    "                game['attendance'] = row.find('td', {'data-stat':'attendance'}).text\n",
    "                game['streak'] = row.find('td', {'data-stat':'win_loss_streak'}).text\n",
    "                game['saving_pitcher'] = row.find('td', {'data-stat':'saving_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "            except:\n",
    "                pass\n",
    "            if game['game#'] != 'Gm#':\n",
    "                season.append(game)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        club.append(pd.DataFrame(season))\n",
    "        sleep(3)\n",
    "    df = pd.concat(club)\n",
    "    df.to_csv(f'../data/{team}_data.csv', index = False)\n",
    "    print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tampa Bay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list3 = ['2008', '2009', '2010', '2011', '2012', \n",
    "              '2013', '2014','2015', '2016', '2017', '2018', '2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tampa_Bay = ['TBR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBR\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "for team in Tampa_Bay:\n",
    "    club = []\n",
    "    print(team)\n",
    "    for year in year_list3:\n",
    "        url = f'https://www.baseball-reference.com/teams/{team}/{year}-schedule-scores.shtml'\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.content)\n",
    "        season= []\n",
    "\n",
    "        for row in soup.find('div', {'id':'all_team_schedule'}).find('tbody').find_all('tr'):\n",
    "            game = {}\n",
    "            try:\n",
    "                game['game#'] = row.find('th', {'data-stat':'team_game'}).text\n",
    "                game['day'] = (row.find('td', {'data-stat':'date_game'}).text).split()[0].strip(',')\n",
    "                game['date'] = row.find('td').attrs['csk']\n",
    "                game['team'] = row.find('td', {'data-stat':'team_ID'}).text\n",
    "                game['home_away'] = row.find('td', {'data-stat':'homeORvis'}).text\n",
    "                game['opp'] = row.find('td', {'data-stat':'opp_ID'}).text\n",
    "                game['win_loss'] = row.find('td', {'data-stat':'win_loss_result'}).text\n",
    "                game['r'] = row.find('td', {'data-stat':'R'}).text\n",
    "                game['ra'] = row.find('td', {'data-stat':'RA'}).text\n",
    "                game['innings'] = row.find('td', {'data-stat':'extra_innings'}).text\n",
    "                game['record'] = row.find('td', {'data-stat':'win_loss_record'}).text\n",
    "                game['divison_rank'] = row.find('td', {'data-stat':'rank'}).text\n",
    "                game['games_back'] = row.find('td', {'data-stat':'games_back'}).text\n",
    "                game['winning_pitcher'] = row.find('td', {'data-stat':'winning_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "                game['losing_pitcher'] = row.find('td', {'data-stat':'losing_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "                game['game_duration'] = row.find('td', {'data-stat':'time_of_game'}).text\n",
    "                game['day_night'] = row.find('td', {'data-stat':'day_or_night'}).text\n",
    "                game['attendance'] = row.find('td', {'data-stat':'attendance'}).text\n",
    "                game['streak'] = row.find('td', {'data-stat':'win_loss_streak'}).text\n",
    "                game['saving_pitcher'] = row.find('td', {'data-stat':'saving_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "            except:\n",
    "                pass\n",
    "            if game['game#'] != 'Gm#':\n",
    "                season.append(game)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        club.append(pd.DataFrame(season))\n",
    "        sleep(3)\n",
    "    df = pd.concat(club)\n",
    "    df.to_csv(f'../data/{team}_data.csv', index = False)\n",
    "    print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arizona Diamondbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arizona = ['ARI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list4 = ['1998', '1999',\n",
    "    '2000', '2001', '2002', '2003', '2004',\n",
    "    '2005', '2006', '2007', '2008', '2009',\n",
    "    '2010', '2011', '2012', '2013', '2014',\n",
    "    '2015', '2016', '2017', '2018', '2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "for team in Arizona:\n",
    "    club = []\n",
    "    print(team)\n",
    "    for year in year_list4:\n",
    "        url = f'https://www.baseball-reference.com/teams/{team}/{year}-schedule-scores.shtml'\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.content)\n",
    "        season= []\n",
    "\n",
    "        for row in soup.find('div', {'id':'all_team_schedule'}).find('tbody').find_all('tr'):\n",
    "            game = {}\n",
    "            try:\n",
    "                game['game#'] = row.find('th', {'data-stat':'team_game'}).text\n",
    "                game['day'] = (row.find('td', {'data-stat':'date_game'}).text).split()[0].strip(',')\n",
    "                game['date'] = row.find('td').attrs['csk']\n",
    "                game['team'] = row.find('td', {'data-stat':'team_ID'}).text\n",
    "                game['home_away'] = row.find('td', {'data-stat':'homeORvis'}).text\n",
    "                game['opp'] = row.find('td', {'data-stat':'opp_ID'}).text\n",
    "                game['win_loss'] = row.find('td', {'data-stat':'win_loss_result'}).text\n",
    "                game['r'] = row.find('td', {'data-stat':'R'}).text\n",
    "                game['ra'] = row.find('td', {'data-stat':'RA'}).text\n",
    "                game['innings'] = row.find('td', {'data-stat':'extra_innings'}).text\n",
    "                game['record'] = row.find('td', {'data-stat':'win_loss_record'}).text\n",
    "                game['divison_rank'] = row.find('td', {'data-stat':'rank'}).text\n",
    "                game['games_back'] = row.find('td', {'data-stat':'games_back'}).text\n",
    "                game['winning_pitcher'] = row.find('td', {'data-stat':'winning_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "                game['losing_pitcher'] = row.find('td', {'data-stat':'losing_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "                game['game_duration'] = row.find('td', {'data-stat':'time_of_game'}).text\n",
    "                game['day_night'] = row.find('td', {'data-stat':'day_or_night'}).text\n",
    "                game['attendance'] = row.find('td', {'data-stat':'attendance'}).text\n",
    "                game['streak'] = row.find('td', {'data-stat':'win_loss_streak'}).text\n",
    "                game['saving_pitcher'] = row.find('td', {'data-stat':'saving_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "            except:\n",
    "                pass\n",
    "            if game['game#'] != 'Gm#':\n",
    "                season.append(game)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        club.append(pd.DataFrame(season))\n",
    "        sleep(3)\n",
    "    df = pd.concat(club)\n",
    "    df.to_csv(f'../data/{team}_data.csv', index = False)\n",
    "    print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miami Marlins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Miami = ['MIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list5 = ['2012', '2013', '2014',\n",
    "    '2015', '2016', '2017', '2018', '2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIA\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "for team in Miami:\n",
    "    club = []\n",
    "    print(team)\n",
    "    for year in year_list5:\n",
    "        url = f'https://www.baseball-reference.com/teams/{team}/{year}-schedule-scores.shtml'\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.content)\n",
    "        season= []\n",
    "\n",
    "        for row in soup.find('div', {'id':'all_team_schedule'}).find('tbody').find_all('tr'):\n",
    "            game = {}\n",
    "            try:\n",
    "                game['game#'] = row.find('th', {'data-stat':'team_game'}).text\n",
    "                game['day'] = (row.find('td', {'data-stat':'date_game'}).text).split()[0].strip(',')\n",
    "                game['date'] = row.find('td').attrs['csk']\n",
    "                game['team'] = row.find('td', {'data-stat':'team_ID'}).text\n",
    "                game['home_away'] = row.find('td', {'data-stat':'homeORvis'}).text\n",
    "                game['opp'] = row.find('td', {'data-stat':'opp_ID'}).text\n",
    "                game['win_loss'] = row.find('td', {'data-stat':'win_loss_result'}).text\n",
    "                game['r'] = row.find('td', {'data-stat':'R'}).text\n",
    "                game['ra'] = row.find('td', {'data-stat':'RA'}).text\n",
    "                game['innings'] = row.find('td', {'data-stat':'extra_innings'}).text\n",
    "                game['record'] = row.find('td', {'data-stat':'win_loss_record'}).text\n",
    "                game['divison_rank'] = row.find('td', {'data-stat':'rank'}).text\n",
    "                game['games_back'] = row.find('td', {'data-stat':'games_back'}).text\n",
    "                game['winning_pitcher'] = row.find('td', {'data-stat':'winning_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "                game['losing_pitcher'] = row.find('td', {'data-stat':'losing_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "                game['game_duration'] = row.find('td', {'data-stat':'time_of_game'}).text\n",
    "                game['day_night'] = row.find('td', {'data-stat':'day_or_night'}).text\n",
    "                game['attendance'] = row.find('td', {'data-stat':'attendance'}).text\n",
    "                game['streak'] = row.find('td', {'data-stat':'win_loss_streak'}).text\n",
    "                game['saving_pitcher'] = row.find('td', {'data-stat':'saving_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "            except:\n",
    "                pass\n",
    "            if game['game#'] != 'Gm#':\n",
    "                season.append(game)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        club.append(pd.DataFrame(season))\n",
    "        sleep(3)\n",
    "    df = pd.concat(club)\n",
    "    df.to_csv(f'../data/{team}_data.csv', index = False)\n",
    "    print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expos/Nationals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Washington = ['WSN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'1995', '1996', '1997', '1998', '1999',\n",
    "    '2000', '2001', '2002', '2003', '2004',\n",
    "    '2005', '2006', '2007', '2008', '2009',\n",
    "    '2010', '2011', '2012', '2013', '2014',\n",
    "    '2015', '2016', '2017', '2018', '2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list6 = [\n",
    "    '2005', '2006', '2007', '2008', '2009',\n",
    "    '2010', '2011', '2012', '2013', '2014',\n",
    "    '2015', '2016', '2017', '2018', '2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSN\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "for team in Washington:\n",
    "    club = []\n",
    "    print(team)\n",
    "    for year in year_list6:\n",
    "        url = f'https://www.baseball-reference.com/teams/{team}/{year}-schedule-scores.shtml'\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.content)\n",
    "        season= []\n",
    "\n",
    "        for row in soup.find('div', {'id':'all_team_schedule'}).find('tbody').find_all('tr'):\n",
    "            game = {}\n",
    "            try:\n",
    "                game['game#'] = row.find('th', {'data-stat':'team_game'}).text\n",
    "                game['day'] = (row.find('td', {'data-stat':'date_game'}).text).split()[0].strip(',')\n",
    "                game['date'] = row.find('td').attrs['csk']\n",
    "                game['team'] = row.find('td', {'data-stat':'team_ID'}).text\n",
    "                game['home_away'] = row.find('td', {'data-stat':'homeORvis'}).text\n",
    "                game['opp'] = row.find('td', {'data-stat':'opp_ID'}).text\n",
    "                game['win_loss'] = row.find('td', {'data-stat':'win_loss_result'}).text\n",
    "                game['r'] = row.find('td', {'data-stat':'R'}).text\n",
    "                game['ra'] = row.find('td', {'data-stat':'RA'}).text\n",
    "                game['innings'] = row.find('td', {'data-stat':'extra_innings'}).text\n",
    "                game['record'] = row.find('td', {'data-stat':'win_loss_record'}).text\n",
    "                game['divison_rank'] = row.find('td', {'data-stat':'rank'}).text\n",
    "                game['games_back'] = row.find('td', {'data-stat':'games_back'}).text\n",
    "                game['winning_pitcher'] = row.find('td', {'data-stat':'winning_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "                game['losing_pitcher'] = row.find('td', {'data-stat':'losing_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "                game['game_duration'] = row.find('td', {'data-stat':'time_of_game'}).text\n",
    "                game['day_night'] = row.find('td', {'data-stat':'day_or_night'}).text\n",
    "                game['attendance'] = row.find('td', {'data-stat':'attendance'}).text\n",
    "                game['streak'] = row.find('td', {'data-stat':'win_loss_streak'}).text\n",
    "                game['saving_pitcher'] = row.find('td', {'data-stat':'saving_pitcher'}).find('a').attrs['title'].replace('\\xa0', ' ')\n",
    "            except:\n",
    "                pass\n",
    "            if game['game#'] != 'Gm#':\n",
    "                season.append(game)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        club.append(pd.DataFrame(season))\n",
    "        sleep(3)\n",
    "    df = pd.concat(club)\n",
    "    df.to_csv(f'../data/{team}_data.csv', index = False)\n",
    "    print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
